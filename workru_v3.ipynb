{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://www.rabota.ru'\n",
    "url ='https://www.rabota.ru/?query=Data%20Scientist&sort=relevance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = requests.get(url)\n",
    "if request.status_code == 200:\n",
    "    print('Load is completed')\n",
    "else:\n",
    "    print('Load is not completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "# Calculate the number of pages\n",
    "pages = page.find_all('a', class_='pagination-list__item')\n",
    "\"\"\"Number pages per vacancies\"\"\"\n",
    "pages_lst = []\n",
    "for page in pages:\n",
    "    pages_lst.append(int(*page.text.split()))\n",
    "    \n",
    "page_min = min(pages_lst)\n",
    "page_max = max(pages_lst)\n",
    "\n",
    "print(f'max number of pages: {page_max}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "    \n",
    "for page in range(1, page_max+1):\n",
    "    urls.append(url + '&page=' + str(page))\n",
    "\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_titles = []\n",
    "final_links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = requests.get(urls[10])\n",
    "print(urls[1], request.status_code)\n",
    "page = BeautifulSoup(request.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = page.find_all('h3', class_='vacancy-preview-card__title')\n",
    "links = page.find_all('a', class_=\"vacancy-preview-card__title_border\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_lst = [title.text.strip() for title in titles]\n",
    "links_lst = [(url_base + link.get('href')) for link in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_vacancies(url, url_base):\n",
    "    request = requests.get(url)\n",
    "    if request.status_code == 200:\n",
    "        print('Load is completed')\n",
    "    else:\n",
    "        print('Load is not completed')\n",
    "\n",
    "    page = BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "    # Calculate the number of pages\n",
    "    pages = page.find_all('a', class_='pagination-list__item')\n",
    "    \"\"\"Number pages per vacancies\"\"\"\n",
    "    pages_lst = []\n",
    "    for page in pages:\n",
    "        pages_lst.append(int(*page.text.split()))\n",
    "    \n",
    "    page_min = min(pages_lst)\n",
    "    page_max = max(pages_lst)\n",
    "\n",
    "    print(f'max number of pages: {page_max}')\n",
    "\n",
    "    urls = []\n",
    "    \n",
    "    for page in range(1, page_max+1):\n",
    "        urls.append(url + '&page=' + str(page))\n",
    "\n",
    "    final_titles = []\n",
    "    final_links = []\n",
    "\n",
    "    for u in urls:\n",
    "        request = requests.get(u)\n",
    "        page = BeautifulSoup(request.text, 'html.parser')\n",
    "        titles = page.find_all('h3', class_='vacancy-preview-card__title')\n",
    "        links = page.find_all('a', class_=\"vacancy-preview-card__title_border\")\n",
    "        titles_lst = [title.text.strip() for title in titles]\n",
    "        links_lst = [(url_base + link.get('href')) for link in links]\n",
    "\n",
    "    final_titles.extend(titles_lst)\n",
    "    final_links.extend(links_lst)    \n",
    "    \n",
    "\n",
    "    # vacancy_dict = {x.text.strip():(url_base+y.get('href')) for x, y in zip(titles, links)}\n",
    "\n",
    "    return final_titles, final_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles, locations, salaries, dates = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in final_links:\n",
    "    request = requests.get(link)\n",
    "    page = BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        title = page.find('h1', class_='vacancy-card__title').text.strip()\n",
    "    except AttributeError:\n",
    "        title = None\n",
    "    try:\n",
    "        location = page.find('span', class_='vacancy-requirements__city').text.strip()\n",
    "    except AttributeError:\n",
    "        location = None\n",
    "    try:\n",
    "        salary = page.find('h3', class_='vacancy-card__salary').text.strip()\n",
    "    except AttributeError:\n",
    "        salary = None\n",
    "    try:\n",
    "        date = page.find('span', class_='vacancy-system-info__updated-date').text.strip()\n",
    "    except:\n",
    "        date=None\n",
    "    \n",
    "\n",
    "    titles.append(title)\n",
    "    locations.append(location)\n",
    "    salaries.append(salary)\n",
    "    dates.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'titles':titles, 'locations':locations, 'salaries':salaries, 'dates':dates})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('rabota.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "602538ec380bee7f30cf60ab9cd975200dbef82db9956ec553e95c0b26708ef7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b6a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import fake_useragent\n",
    "\n",
    "ua = fake_useragent.UserAgent()\n",
    "text = 'Machine Learning'\n",
    "\n",
    "def get_url():\n",
    "    for page in range(1,3):\n",
    "        print(f'Log: working over page {page}...')\n",
    "        url = f'https://career.habr.com/vacancies?page={page}&q={text}&type=all'\n",
    "        response = requests.get(url, headers = {'user-agent': ua.random})\n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        data = soup.find_all('a', attrs = {'class': 'vacancy-card__icon-link'})\n",
    "        for i in data:\n",
    "            resume_url = 'https://career.habr.com/' + i.get('href')\n",
    "            yield resume_url\n",
    "\n",
    "def get_resume():\n",
    "    for resume in get_url():\n",
    "        response = requests.get(resume, headers = {'user-agent': ua.random})\n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        data = soup.find('article', class_= 'vacancy-show')\n",
    "        \n",
    "        try:\n",
    "            title = data.find(class_='page-title__title').text\n",
    "        except:\n",
    "            title = ''\n",
    "        try:\n",
    "            employer = data.find(class_ = 'basic-salary basic-salary--appearance-vacancy-header').text\n",
    "        except:\n",
    "            employer = ''\n",
    "        try:\n",
    "            req = data.find_all(class_ = 'link-comp link-comp--appearance-dark')\n",
    "            lst_r = []\n",
    "            for i in req:\n",
    "                lst_r.append(i.text)\n",
    "        except:\n",
    "            req = ''\n",
    "        try:\n",
    "            salary = lst_r[-1]\n",
    "        except:\n",
    "            salary = ''\n",
    "        try:\n",
    "            spec = lst_r[0]\n",
    "        except:\n",
    "            spec = ''\n",
    "        try:\n",
    "            level = lst_r[1]\n",
    "        except:\n",
    "            level = ''\n",
    "        try:\n",
    "            skills = lst_r[2:-1]\n",
    "        except:\n",
    "            skills = ''          \n",
    "           \n",
    "        try:\n",
    "            date_publish = data.find('time').attrs['datetime']\n",
    "        except:\n",
    "            date_publish = ''\n",
    "            \n",
    "        try:\n",
    "            lc = data.find_all(class_ = 'inline-list')\n",
    "            lst_l = []\n",
    "            for i in lc[2]:\n",
    "                lst_l.append(i.text)\n",
    "            location = lst_l[0]\n",
    "            working_day = lst_l[1]\n",
    "            remote = lst_l[2]\n",
    "        except:\n",
    "            location = ''\n",
    "            working_day = ''\n",
    "            remote = ''\n",
    "        try:\n",
    "            employer_desc = data.find(class_ = 'vacancy-company__sub-title').text\n",
    "        except:\n",
    "            employer_desc = ''\n",
    "        try:\n",
    "            lc = data.find(class_ = 'vacancy-description__text').find_all(class_= 'style-ugc')\n",
    "            lst = []\n",
    "            for i in lc:\n",
    "                lst.append(i.text)\n",
    "        except:\n",
    "            lc = ''\n",
    "        try:\n",
    "            respons = lst[0]\n",
    "        except:\n",
    "            respons = ''\n",
    "        try:\n",
    "            compens = lst[1]\n",
    "        except:\n",
    "            compens = ''\n",
    "        \n",
    "        try:\n",
    "            add_info = lst[2]\n",
    "        except:\n",
    "            add_info = ''\n",
    "   \n",
    "            \n",
    "        yield title, spec, salary, employer, level, skills, date_publish, location, working_day, remote,\\\n",
    "              employer_desc, respons, compens, add_info\n",
    "\n",
    "habr = pd.DataFrame(columns = ['title', 'spec', 'employer', 'salary','level','skills', 'date_publish',\\\n",
    "                                'location', 'working_day', 'remote', 'employer_desc','respons','compens',\n",
    "                              'add_info'])\n",
    "for item in get_resume():\n",
    "    resume_data = []\n",
    "    for i in range(14):\n",
    "        resume_data.append(item[i])\n",
    "    habr.loc[len(habr.index)] = resume_data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

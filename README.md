# <center>Описание проекта DATATON_22_boring-wozniak</center>

Мы хотим собрать информацию с разных публичных источников о вакансиях в сфере IT, связанных с наукой о данных. Основным географическим регионом будет Российская Федерация. Собирать будем вакансии по отпределенным тегам. В ходе сбора информации мы хотим оценить разные технические способы сбора из выбранных источников, чтобы посмотреть, какую информацию по рынку вакансий можно получить и какие есть сложности.

Данный проект является первым шагом в работе с данными и может расширяться как географически, так и функционально:

* мы сможем добавить больше регионов
* мы сможем смотреть динамику рынка вакансий, в дальнейшем делая срезы рынка из выбранных источников с определенной периодичностью
* мы сможем подключить базу данных для хранения информации

<img src="https://www.hillwebcreations.com/wp-content/uploads/2020/09/the-value-of-market-research-for-seo.jpg"  width="400" height="200">

# Этапы проекта:

1. Сбор инфорамции о вакансиях с публичных сайтов по тегам [Data Science, Data Analyst, Data Engineer, Machine Learning, MLOps, Аналитик данных, Инженер по данным]. Наше решение - мы собираем максимально возможное количество данных, чтобы потом решить какие из них мы будем использовать в объединенном датасете на постоянной основе. Основные источники наших данных:

    * сайт [career.habr.com](https://career.habr.com) - сайт, который помогает найти работу мечты в IT. Сайт содержит более 3 340 вакансий. Для его парсинга по тегам использовался вот этот парсер [parser](https://github.com/shakhovak/DATATON_22_boring-wozniak/blob/master/parsers_used/HABR_parser.ipynb). С него мы получили более 1 000 вакансии для последующего объединения.

    * сайт [superjob.ru](https://www.superjob.ru/) - это лучшие предложения высокооплачиваемой работы от российских и  зарубежных компаний. Собрали 20 вакансий. Данные собирали с помощью [API](https://github.com/shakhovak/DATATON_22_boring-wozniak/blob/master/parsers_used/superjob_get_data.ipynb) для этого сайта.

    * сайт [rabota.ru](https://www.rabota.ru) - найдем работу за вас. Для сбора данных мы сделали [пасрер](https://github.com/shakhovak/DATATON_22_boring-wozniak/blob/master/parsers_used/zarpalata_ru_api.ipynb) этого сайта на базе API тестовой и продуктивной сред. Анализ бесплатной версии API показал, что для задач дататона не получится собрать полезные данные, так как API позволяет работать с ваканиями только за последний месяц и среди них очень вакансий, связанных с ML & DS. Результаты работы приложены в виде ноутбука к проекту на случай, если появятся задачи, которые сможет решить имеющийся API.

    * [Telegram канал](https://t.me/datasciencejobs) - лучшие вакансии по Data Science, ML, CV, AI ... Для сборки использовался скраппинг на основе Selenium с помощью вот этого [парсера](https://github.com/shakhovak/DATATON_22_boring-wozniak/blob/master/parsers_used/telegram-scrapper.ipynb). С него мы получили несколько более 800 вакансий.

    * сайт [hh.ru](https://hh.ru) - один из самых популярных источников вакансий. Мы использовали API для этого сайта и с помощью парсера получили почти 1000 вакансий.

2. Анализ собранных данных. На этом этапе мы смотрим, какие данные нам удалось собрать, анализируем их характеристики и принимаем решение, какие из них остатся в объединенном датасете. 

    Мы проанализровали данные из разных источников и решили оставить следующие характеристики для объединения:

    * company - работодатель
    * poistion - название позиции
    * location - место работы
    * format - удаленный, в офисе или гибридный
    * salary - уровень заработной платы
    * schedule - график работы
    * level - уровень потенциального сотрудника 
    * techstack - ключевые навыки
    * date_publish - дата публикации
    * source_id - источник информации

По итогам объединения получился [датасет](https://drive.google.com/file/d/1TcWn-SIgbqQWkn2sNpWR1jMOIf5qhfvb/view?usp=sharing) в 5990 строк.

3. Анализируем сводный датасет и выводим некоторые характеристики рынка вакансий в регионе.

Несмотря на то, что в нашем датасете было много ограничений (ограничения по времени при выгрузке вакансий, часть данных мы отбросили при объединении), нам удалось получить интересные выводы, которые могут, на наш взгляд, использоваться для характеристики рынка вакансий.

Итак, какого же сотрудника ищут сегодня компании для работы с данными?

**Прежде всего, это сотрудник уровня Middle, владеющий Python и SQL. Его ждут в первую очередь в Москве и Санкт-Петербурге, при этом готовы предлагать и удаленную работу и гибкий график, не сильно жертвуя уровнем заработной платы. С высокой вероятностью, должность этого сотрудника будет аналитик**.

Мы считаем, что полученный датасет позволит в дальнейшем прослеживать динамику на рынке вакансий даже в том усеченном варианте, которые мы использовали в проекте. 

Полный анализ можно посмотреть в [ноутбуке](https://github.com/shakhovak/DATATON_22_boring-wozniak/blob/master/FINAL%20SUMMARY.ipynb).
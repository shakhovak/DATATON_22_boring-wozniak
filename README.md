# <center>Описание проекта DATATON_22_boring-wozniak</center>

# Цель проекта

Мы хотим собрать информацию с разных публичных источников о вакансиях в сфере IT, связанных с наукой о данных. Основным географическим регионом будут страны ЕАС. Собирать будем вакансии по отпределенным тегам. 
Данный проект является первым шагом в работе с данными и может расширяться как географически, так и функционально:

* мы сможем добавть больше регионов
* мы сможем смотреть динамику рынка вакансий, в дальнейшем делая срезы рынка из используемых источников с определенной периодичностью
* мы сможем подключить базу данных для хранения информации

# Этапы проекта:

1. Сбор инфорамции о вакансиях с публичных сайтов по тегам [Data Science, Data Analyst, Data Engineer, Machine Learning, MLOps, Аналитик данных, Инженер по данным]. Наше решение - мы собираем максимально возможное количество данных, чтобы потом решить какие из них мы будем использовать в объединенном датасете на постоянной основе. Основные источники наших данных:

    * сайт [career.habr.com](https://career.habr.com) - сайт, который помогает найти работу мечты в IT. Сайт содержит более 3 340 вакансий. Для его парсинга по тегам использовался вот этот парсер [parser](https://github.com/shakhovak/DATATON_22_boring-wozniak/blob/master/HABR_parser.ipynb). С него мы получили более 1 000 вакансии для последующего объединения.

    * сайт [superjob.ru](https://www.superjob.ru/) - это лучшие предложения высокооплачиваемой работы от российских и  зарубежных компаний. Собрали 20 вакансий. Данные собирали с помощью API для этого сайта.

    * сайт [rabota.ru](https://www.rabota.ru/) - найдем работу за вас. Для сбора данных использовался метод скраппинга и удалось собрать 300 вакансий. Для работы использовался [парсер](https://github.com/shakhovak/DATATON_22_boring-wozniak/blob/master/workru_v3.ipynb).

    * [Telegram канал](https://t.me/datasciencejobs) - лучшие вакансии по Data Science, ML, CV, AI ... Для сборки использовался скраппинг на основе Selenium. С него мы получили несколько сотен вакансий.

    * сайт [hh.ru](https://hh.ru) - один из самых популярных источников вакансий. Мы использовали API для этого сайта и с помощью парсера получили почти 1000 вакансий.

2. Анализ собранных данных. На этом этапе мы смотрим, какие данные нам удалось собрать, анализируем их характеристики и принимаем решение, какие из них остатся в объединенном датасете. 

Мы проанализровали данные из разных источников и решили оставить следующие характеристики для объединения:

   * company - работодатель
   * poistion - название позиции
   * location - место работы
   * format - удаленный, в офисе или гибридный
   * salary - уровень заработной платы
   * schedule - график работы
   * level - уровень потенциального сотрудника 
   * techstack - ключевые навыки
   * date_publish - дата публикации
   * source_id - источник информации

По итогам объединения получился датасет в ХХ строк ссылка

3. Анализируем сводный датасет и выводим некоторые характеристики рынка вакансий в регионе.